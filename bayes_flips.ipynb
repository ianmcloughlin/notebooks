{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Coin Flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian statistics provides a framework for updating beliefs based on new evidence.  \n",
    "Let's use coin flips to illustrate how Bayesian inference works.\n",
    "\n",
    "Imagine we have a coin, but we don’t know if it’s fair or biased.  \n",
    "We want to estimate the probability $p$ that the coin lands heads up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical arrays.\n",
    "import numpy as np\n",
    "\n",
    "# Plots.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Statistical distributions.\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Bayesian statistics.\n",
    "import pymc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "x = np.linspace(0, 1, 1000)  # Values of p from 0 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Belief\n",
    "\n",
    "In Bayesian statistics, we start with a **prior belief** about $p$, the probability of heads.  \n",
    "This belief can be based on past knowledge, intuition, or be vague.  \n",
    "\n",
    "For simplicity, let’s assume we don't know much about the coin.  \n",
    "Then we use a **uniform prior** over $p$.  \n",
    "This means we believe that any probability between 0 and 1 is equally likely.  \n",
    "\n",
    "$P(p) = 1 \\quad \\text{for} \\, 0 \\leq p \\leq 1$\n",
    "\n",
    "This is our prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: 10 flips, 7 heads\n",
    "n = 10  # Total flips\n",
    "k = 7   # Heads observed\n",
    "\n",
    "# Prior: Uniform distribution (Beta(1, 1))\n",
    "a_prior, b_prior = 1, 1\n",
    "\n",
    "# Prior distribution (Beta(1, 1))\n",
    "prior = stats.beta.pdf(x, a_prior, b_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "\n",
    "Suppose we flip the coin $n$ times and observe $k$ heads.  \n",
    "The likelihood function represents the probability of seeing $k$ heads out of $n$ flips, given $p$.  \n",
    "\n",
    "This follows a binomial distribution:  \n",
    "\n",
    "$P(\\text{data} \\mid p) = \\binom{n}{k} p^k (1 - p)^{n - k}$  \n",
    "\n",
    "This is the likelihood of observing the data (number of heads) given the parameter $p$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Distribution\n",
    "\n",
    "Using Bayes' Theorem, we update our belief about $p$ after observing the data.  \n",
    "Bayes' Theorem is:  \n",
    "\n",
    "$P(p \\mid \\text{data}) = \\frac{P(\\text{data} \\mid p) P(p)}{P(\\text{data})}$\n",
    "\n",
    "Where:  \n",
    "\n",
    "- $P(p \\mid \\text{data})$ is the **posterior distribution**, which represents our updated belief about $p$ after seeing the data.\n",
    "\n",
    "- $P(\\text{data} \\mid p)$ is the **likelihood**, which we just defined.\n",
    "\n",
    "- $P(p)$ is the **prior**.\n",
    "\n",
    "- $P(\\text{data})$ is the **evidence**, a normalizing constant that ensures the posterior is a valid probability distribution.\n",
    "\n",
    "\n",
    "Since the evidence is just a constant and doesn't affect the shape of the posterior, we focus on the numerator:  \n",
    "$P(p \\mid \\text{data}) \\propto P(\\text{data} \\mid p) P(p)$\n",
    "\n",
    "For our example with a uniform prior, the posterior simplifies to:  \n",
    "$P(p \\mid \\text{data}) \\propto p^k (1 - p)^{n - k}$\n",
    "\n",
    "This is a **Beta distribution**, specifically:  \n",
    "$P(p \\mid \\text{data}) \\sim \\text{Beta}(k + 1, n - k + 1)$  \n",
    "\n",
    "The Beta distribution is the conjugate prior for the binomial distribution, meaning that if you start with a Beta prior, the posterior will also be Beta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior: Beta(k + a_prior, n - k + b_prior)\n",
    "a_post = k + a_prior\n",
    "b_post = n - k + b_prior\n",
    "\n",
    "# Posterior distribution (Beta(k + 1, n - k + 1))\n",
    "posterior = stats.beta.pdf(x, a_post, b_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "Before observing any flips, we had no preference for any particular value of $p$ (uniform prior).  \n",
    "\n",
    "After observing $k$ heads and $n-k$ tails, the posterior distribution represents our updated belief about $p$.  \n",
    "The more flips we observe, the more confident we become about the true value of $p$.  \n",
    "\n",
    "For example, if you observe 7 heads out of 10 flips, the posterior would be $\\text{Beta}(8, 4)$.  \n",
    "This distribution peaks around $p = 0.7$, reflecting our updated belief that the coin might be biased toward heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prior and posterior\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, prior, label=f'Prior Beta({a_prior}, {b_prior})', linestyle='--')\n",
    "plt.plot(x, posterior, label=f'Posterior Beta({a_post}, {b_post})', color='blue')\n",
    "plt.fill_between(x, posterior, alpha=0.3, color='blue')\n",
    "\n",
    "plt.title('Bayesian Inference of Coin Flips')\n",
    "plt.xlabel('Probability of heads (p)')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code:\n",
    "\n",
    "1. **Data**: We have 10 flips and observed 7 heads.\n",
    "\n",
    "2. **Prior**: We assume a uniform prior, which is equivalent to a `Beta(1, 1)` distribution.\n",
    "\n",
    "3. **Posterior**: The posterior after observing 7 heads out of 10 flips is `Beta(8, 4)`.\n",
    "\n",
    "4. **Plotting**: We plot both the prior and the posterior to visualize how the prior belief is updated by the data.\n",
    "\n",
    "\n",
    "### Expected Output:\n",
    "\n",
    "- The prior will be a flat line since we assumed all values of $p$ are equally likely (uniform distribution).\n",
    "\n",
    "- The posterior will peak around $p$, reflecting the fact that we observed 7 heads in 10 flips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Inference in Practice\n",
    "\n",
    "1. **Start with a prior**: Your initial belief about the parameter (e.g., $p$).\n",
    "\n",
    "2. **Collect data**: Flip the coin several times.\n",
    "\n",
    "3. **Update your prior**: Use the likelihood of the data to update your prior, resulting in a posterior distribution.\n",
    "\n",
    "4. **Make decisions**: Use the posterior distribution to make probabilistic statements about $p$ or to predict future outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Beta distribution for various values of a and b.\n",
    "for a, b in [(2, 5), (1, 1), (2, 2), (5, 2)]:\n",
    "    y = stats.beta.pdf(x, a, b)\n",
    "    plt.plot(x, y, label=f'Beta({a},{b})')\n",
    "\n",
    "# Title.\n",
    "plt.title('Beta Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: 10 flips, 7 heads\n",
    "n = 10  # Total flips\n",
    "k = 7   # Heads observed\n",
    "\n",
    "# Bayesian model using PyMC\n",
    "with pymc.Model() as model:\n",
    "    # Prior: Uniform distribution for the probability of heads\n",
    "    p = pymc.Beta('p', alpha=1, beta=1)\n",
    "    \n",
    "    # Likelihood: Binomial likelihood based on observed data (k heads out of n flips)\n",
    "    obs = pymc.Binomial('obs', n=n, p=p, observed=k)\n",
    "    \n",
    "    # Inference: Perform sampling to estimate the posterior distribution\n",
    "    trace = pymc.sample(1000, return_inferencedata=False, progressbar=False)\n",
    "\n",
    "# Posterior distribution\n",
    "posterior_samples = trace['p']\n",
    "\n",
    "# Plot posterior distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(posterior_samples, bins=30, density=True, alpha=0.7, color='blue')\n",
    "plt.title('Posterior distribution of probability of heads (p)')\n",
    "plt.xlabel('p (probability of heads)')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In Bayesian statistics:  \n",
    "\n",
    "- You **start with a prior** belief.\n",
    "\n",
    "- You **update this belief** with new evidence (coin flips) using Bayes' Theorem.\n",
    "\n",
    "- The result is a **posterior distribution**, representing your new belief about the probability of heads.\n",
    "\n",
    "\n",
    "This framework is powerful because it continuously updates with more data, allowing you to refine your estimate of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
